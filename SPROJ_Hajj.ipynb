{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JibKh/SPROJ-Hajj/blob/master/SPROJ_Hajj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogNK5nPyLKrB"
      },
      "source": [
        "# Check GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR9h45BnLMst"
      },
      "source": [
        "The GPU must NOT be Tesla K80. If it is then factory reset runtime and try again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/omarmukhtar/Documents/hajjProject/SPROJ-Hajj\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgcsv1  = pd.read_csv(\"./NWPU-Crowd-Sample-Code/Final_Results/data_000002.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(703, 1280)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imgcsv1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "unknown file extension: ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m~/anaconda3/envs/hajjenv/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2214\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m                 \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEXTENSION\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2216\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ''",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_4198/2441863191.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./NWPU-Crowd-Sample-Code/Final_Results/data_000002.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# image_1 = imread('path to read image as Ex: output.png')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# # plot raw pixel data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/hajjenv/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi)\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mbackground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1516\u001b[0;31m             \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/hajjenv/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2215\u001b[0m                 \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEXTENSION\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2216\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2217\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"unknown file extension: {ext}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSAVE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: unknown file extension: "
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "from numpy import genfromtxt\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "my_data = genfromtxt('./NWPU-Crowd-Sample-Code/Final_Results/data_000002.csv', delimiter=',')\n",
        "matplotlib.image.imsave('./', my_data, cmap='gray')\n",
        "# image_1 = imread('path to read image as Ex: output.png')\n",
        "# # plot raw pixel data\n",
        "# pyplot.imshow(image_1)\n",
        "# # show the figure\n",
        "# pyplot.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy import genfromtxt\n",
        "my_data = genfromtxt('./NWPU-Crowd-Sample-Code/Final_Results/data_000002.csv', delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(my_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/omarmukhtar/Documents/hajjProject/SPROJ-Hajj\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/omarmukhtar/anaconda3/envs/hajjenv/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning:     `imsave` is deprecated!\n",
            "    `imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``imageio.imwrite`` instead.\n",
            "  \"\"\"\n"
          ]
        }
      ],
      "source": [
        "# from PIL import Image\n",
        "# im = Image.fromarray(my_data)\n",
        "# im.save(\"your_file.jpeg\")\n",
        "import scipy.misc\n",
        "scipy.misc.imsave('outfile.jpg', my_data)\n",
        "# scipy.misc.imwrite('outfile.jpg', my_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install ncvv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6AYibX0sYcH",
        "outputId": "773cf235-ecf4-4216-8563-b6ad48b7ab8d"
      },
      "outputs": [],
      "source": [
        "# !nvcc --version\n",
        "# !nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78C23XEP2kQv"
      },
      "source": [
        "# User Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b9cX_qfLjHsu"
      },
      "outputs": [],
      "source": [
        "# If you have a video put 1. If you have frames put 2.\n",
        "# Based on your choice, update the below cells accordingly\n",
        "video_frames = 1\n",
        "\n",
        "# If you would like to visualize the flow frames. This WILL DELETE ALL THE FLOWFRAMES GENERATED TO SAVE STORAGE.\n",
        "visualize = False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hCEEb0v2wYas"
      },
      "outputs": [],
      "source": [
        "# Video Input\n",
        "\n",
        "if video_frames == 1:\n",
        "\n",
        "  video_name = 'test2.mp4' # If you have a video you want to run inference on. Please include .mp4 or whatever extension the video has.\n",
        "  video_local_gdrive = 2 # If you want to upload a video from your local drive, choose 1. If from your google drive, choose 2. If some other option, go to section \"Upload Video\".\n",
        "  \n",
        "  # If your video is on gdrive, please add Gdrive ID here.\n",
        "  if video_local_gdrive == 2:\n",
        "    video_gdrive = '1lT1MDLqteLpRld10q2cWhdf3Erzrj9O9' # File_id for your google drive video. Use this link to see how to get file ID https://docs.meiro.io/books/meiro-integrations/page/where-can-i-find-the-file-id-on-google-drive#:~:text=To%20locate%20the%20File%20ID,%3D%60%20is%20the%20File%20ID.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lviH4LCUwWmB"
      },
      "outputs": [],
      "source": [
        "# # Frames Input\n",
        "\n",
        "# if video_frames == 2:\n",
        "\n",
        "#   # Mount Gdrive\n",
        "#   from google.colab import drive\n",
        "#   drive.mount('/content/drive')\n",
        "\n",
        "#   frames_zip_name = \"2 - Arabic.zip\" # If you have the frames, enter its zip file here. For ex: \"3 - Video.zip\"\n",
        "#   frames_directory = '../gdrive/My Drive/Hajj Videos/Frames/' # Where the frames are located. If its in gdrive: '../gdrive/My Drive/Location of Zip/' Change the Location of Zip to wherever yours is stored.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WjCyiIBPwhsR"
      },
      "outputs": [],
      "source": [
        "# Skip / Average Options\n",
        "\n",
        "no_frames_skip = 1 # How many frames you want skipped. For eg if its 2 then from frames 1,2,3,4,5,6,7 we take frames 1,4,7. Leave at None to not skip frames.\n",
        "\n",
        "# Only one can work at a time\n",
        "no_average_frames = None # How many frames you want to average. Leave at None if you don't want to avg.\n",
        "running_average = False # If you want to visually see running average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFhOiS9EvPyJ",
        "outputId": "55205c0d-fdb8-4e4b-e694-53538812eaa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lT1MDLqteLpRld10q2cWhdf3Erzrj9O9\n",
            "To: /content/test2.mp4\n",
            "9.70MB [00:00, 18.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# # DO NOT TOUCH\n",
        "\n",
        "# flow_video_name = 'flowvid.mp4'\n",
        "\n",
        "# # FOR VIDEOS\n",
        "# if video_frames == 1:\n",
        "\n",
        "#   # This will prompt you to upload the video from your local machine\n",
        "#   if video_local_gdrive == 1:\n",
        "\n",
        "#     from google.colab import files\n",
        "#     uploaded = files.upload()\n",
        "#     if video_name != list(uploaded.keys())[0]:\n",
        "#       video_name = list(uploaded.keys())[0]\n",
        "\n",
        "#   # This downloads the gdrive video\n",
        "#   elif video_local_gdrive == 2:\n",
        "\n",
        "#     # This will download the video\n",
        "#     !gdown --id $video_gdrive\n",
        "\n",
        "# # FOR FRAMES\n",
        "# if video_frames == 2:\n",
        "  \n",
        "#   !mkdir -p ./frames\n",
        "#   unzip_file = frames_directory + frames_zip_name\n",
        "#   !unzip '$unzip_file' -d ./frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CiX1DcSQ2sye"
      },
      "outputs": [],
      "source": [
        "# # THIS WILL DELETE ALL THE FRAMES, FLOW FRAMES, OUTPUT FILES, FLOW VIDEO.\n",
        "# # If you would like to keep something, make sure to comment it out and save it before running this.\n",
        "\n",
        "# # To restart and run again. Change any parameters above and then go click the \"User Input and Restart\" cell. Then Runtime -> Run After.\n",
        "\n",
        "# !rm -r ./frames\n",
        "# !rm -r ./Flo\n",
        "# !rm -r ./FlowFrames\n",
        "# !rm -r ./output\n",
        "# # !rm ./$video_name\n",
        "# !rm -r ./Average_Frames\n",
        "# !rm -r ./Running_Avg_Frames\n",
        "# !rm -r ./FlowVideo\n",
        "# !pip install setproctitle colorama scipy==1.1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gE_PzuiNKF4"
      },
      "source": [
        "# Setup Video / Frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ODrjmF5NOC5"
      },
      "source": [
        "## Setup Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFfa5R6tNOC5"
      },
      "source": [
        "Converting video to frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_vuJWgkTNOC5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if video_frames == 1:\n",
        "  def mkdir_ifnotexists(dir):\n",
        "      if os.path.exists(dir):\n",
        "          return\n",
        "      os.mkdir(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JmnYMaDJNODA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
            "  configuration: --prefix=/home/omarmukhtar/anaconda3/envs/base02 --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
            "  libavutil      56. 51.100 / 56. 51.100\n",
            "  libavcodec     58. 91.100 / 58. 91.100\n",
            "  libavformat    58. 45.100 / 58. 45.100\n",
            "  libavdevice    58. 10.100 / 58. 10.100\n",
            "  libavfilter     7. 85.100 /  7. 85.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  7.100 /  5.  7.100\n",
            "  libswresample   3.  7.100 /  3.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'test2.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp41isom\n",
            "    creation_time   : 2020-10-06T09:03:00.000000Z\n",
            "  Duration: 00:00:15.33, start: 0.000000, bitrate: 5060 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1280x720 [SAR 1:1 DAR 16:9], 5059 kb/s, 30 fps, 30 tbr, 30k tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-05-10T01:02:34.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : AVC Coding\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to './frames/frame_%06d.png':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp41isom\n",
            "    encoder         : Lavf58.45.100\n",
            "    Stream #0:0(und): Video: png, rgb24, 1280x720 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-05-10T01:02:34.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc58.91.100 png\n",
            "frame=  460 fps=9.8 q=-0.0 Lsize=N/A time=00:00:15.33 bitrate=N/A speed=0.326x    \n",
            "video:748349kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
          ]
        }
      ],
      "source": [
        "if video_frames == 1:\n",
        "  vid_file = video_name\n",
        "  frame_pth = './frames'\n",
        "  mkdir_ifnotexists(frame_pth)\n",
        "  cmd = \"ffmpeg -i %s -start_number 0 -vsync 0 %s/frame_%%06d.png\" % (\n",
        "              vid_file,\n",
        "              frame_pth,\n",
        "          )\n",
        "  os.system(cmd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr47ObqgrBTE",
        "outputId": "9b112766-899a-404d-a19e-0b17775b768c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'test.mp4': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm test.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t60sUMuNRLZ"
      },
      "source": [
        "## Setup Frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZzEI0oeNRLZ"
      },
      "source": [
        "Rename Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTa3YYfiNRLa",
        "outputId": "3e16ad3b-dd05-4b8d-c57b-d371d6298ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "460\n"
          ]
        }
      ],
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I6MZlFeuNRLa"
      },
      "outputs": [],
      "source": [
        "if video_frames == 2:\n",
        "  import os\n",
        "\n",
        "  file_dir = \"./frames/\"\n",
        "  for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "    # print(filename)\n",
        "    if filename[-11:] == \"_UTC+01.jpg\":\n",
        "      src = file_dir + filename\n",
        "      dst = file_dir + str(count).zfill(6) + '.png'\n",
        "      os.rename(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44Yctdz7NRLb",
        "outputId": "3ebe1001-49c0-49c1-b295-61d2bd98c393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "460\n"
          ]
        }
      ],
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pyBrSUVNRLb"
      },
      "source": [
        "Skip Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enywSfQ6NRLb",
        "outputId": "304e4c63-cb1d-4179-db51-9dd0a6ea9028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "460\n"
          ]
        }
      ],
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "knL6MOOQNRLb"
      },
      "outputs": [],
      "source": [
        "if no_frames_skip != None:\n",
        "  directory = \"./frames\"\n",
        "\n",
        "  temp_skip = no_frames_skip\n",
        "\n",
        "  for i, file in enumerate(sorted(os.listdir(directory))):\n",
        "    if (temp_skip != 0) and (file[-4:] == \".png\"):\n",
        "      os.remove(directory + '/' + file)\n",
        "      temp_skip = temp_skip - 1\n",
        "      continue\n",
        "    temp_skip = no_frames_skip\n",
        "\n",
        "\n",
        "# if no_frames_skip != None:\n",
        "#   directory = './frames'\n",
        "#   # no_frames_skip = 2\n",
        "\n",
        "#   for i, file in enumerate(sorted(os.listdir(directory))):\n",
        "#     if (file[-4:] == \".png\") and (int(file[0:-4]) % no_frames_skip == 0):\n",
        "#       # print(file)\n",
        "#       os.remove(directory+'/' + file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uxY5ICzwNRLb"
      },
      "outputs": [],
      "source": [
        "if no_frames_skip != None:\n",
        "  import os\n",
        "\n",
        "  file_dir = \"./frames/\"\n",
        "  for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "    # print(filename)\n",
        "    if filename[-4:] == \".png\":\n",
        "      src = file_dir + filename\n",
        "      dst = file_dir + str(count).zfill(6) + '.png'\n",
        "      os.rename(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQpbfMeRNRLc",
        "outputId": "4f8625ea-a2a6-4154-fed4-861c67990184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "230\n"
          ]
        }
      ],
      "source": [
        "!ls ./frames | wc -l # Use to recheck if number of frames is consistent and nothing went wrong."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUf1OTRXElWr"
      },
      "source": [
        "# NWPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3M14FnKfsHI"
      },
      "source": [
        "## Resized Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcTSrn5hNxCA",
        "outputId": "423bd7eb-45d8-437e-b6ef-c1c6acbaa0a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1280, 704)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# FlowNet outputs frames in multiples of 64. So we ensure it matches that for NWPU also.\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "img = Image.open(\"./frames/000000.png\")\n",
        "\n",
        "# New Sizes\n",
        "x = (img.size[0] // 64) * 64\n",
        "y = (img.size[1] // 64) * 64\n",
        "\n",
        "x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6SlK-azbgHVy"
      },
      "outputs": [],
      "source": [
        "dir = \"./frames\"\n",
        "\n",
        "for frame in sorted(os.listdir(dir)):\n",
        "  if frame[-3:] == 'png':\n",
        "\n",
        "    # Open image and resize\n",
        "    image = Image.open(dir + \"/\" + frame)\n",
        "    new_image = image.resize((x, y))\n",
        "\n",
        "    # Remove image and write new one\n",
        "    os.remove(dir + \"/\" + frame)\n",
        "    new_image.save(dir + \"/\" + frame)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8LDp_Ryq8Cm"
      },
      "source": [
        "## Setup text file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "svT7wMpoq9tb"
      },
      "outputs": [],
      "source": [
        "f = open(\"./frames/test1.txt\", \"w\")\n",
        "\n",
        "i = 0\n",
        "for frame in sorted(os.listdir(\"./frames\")):\n",
        "\n",
        "  if frame[-3:] == 'png':\n",
        "\n",
        "    if i != 0:\n",
        "      f.write(\"\\n\")\n",
        "      \n",
        "    f.write(frame[:-4])\n",
        "    i += 1\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctFBGklsjl3c"
      },
      "source": [
        "## Import NWPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LsKZi0pThUQL"
      },
      "outputs": [],
      "source": [
        "# !gdown --id '1-QsJ4EHwMBwDRQl7bMeCkI0gvUtM2eGZ'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cXIG2U6qp7N7"
      },
      "outputs": [],
      "source": [
        "# !unzip NWPU.zip\n",
        "# !rm NWPU.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtdQClnhu1Cr"
      },
      "source": [
        "## Do NWPU Stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vdCjDvbZRDwN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/omarmukhtar/Documents/hajjProject/SPROJ-Hajj/NWPU-Crowd-Sample-Code\n"
          ]
        }
      ],
      "source": [
        "%cd NWPU-Crowd-Sample-Code/\n",
        "# !mkdir Final_Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before_dividing_by_mask.csv\n",
            "before_last_for_loop_crop_preds.csv\n",
            "CANNet-all_ep_243_mae_93.6_mse_489.9_nae_0.382.pth\n",
            "config.py\n",
            "data.csv\n",
            "datasets\n",
            "Final_Results\n",
            "image_blending.py\n",
            "__init__.py\n",
            "LICENSE\n",
            "MCNN-all_ep_907_mae_218.5_mse_700.6_nae_2.005.pth\n",
            "misc\n",
            "model_out.pth\n",
            "models\n",
            "__pycache__\n",
            "README.md\n",
            "requirements.txt\n",
            "sample\n",
            "saved_exp_para\n",
            "SFCN+-all_ep_321_mae_90.7_mse_487.2_nae_0.375.pth\n",
            "test\n",
            "test_data_sample\n",
            "testing\n",
            "test.py\n",
            "trainer.py\n",
            "train.py\n",
            "validation.py\n",
            "val.txt\n",
            "Video_Maker.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip3 install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# torch.cuda.is_available()\n",
        "# /home/omarmukhtar/Documents/hajjProject/SPROJ-Hajj/frames/test1.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "61ngURUZu22Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/omarmukhtar/anaconda3/envs/hajjenv/lib/python3.7/site-packages/torch/_tensor.py:490: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n",
            "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n",
            "/home/omarmukhtar/anaconda3/envs/hajjenv/lib/python3.7/site-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "predicted count:  220.490078125\n",
            "i in tesst:  576\n",
            "000000 220.4901\n",
            "predicted count:  218.59533203125\n",
            "i in tesst:  576\n",
            "000001 218.5953\n",
            "predicted count:  218.59533203125\n",
            "i in tesst:  576\n",
            "000002 218.5953\n"
          ]
        }
      ],
      "source": [
        "# Edit dataRoot, result_path, model_path, txtpath variables in test.py\n",
        "!python test.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m7rlOWslUMU_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: cannot move 'Final_Results' to '/content/': Permission denied\n",
            "/home/omarmukhtar/Documents/hajjProject/SPROJ-Hajj\n",
            "mv: cannot stat 'Final_Results': No such file or directory\n",
            "rm: cannot remove '/content/frames/test1.txt': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mv Final_Results /content/\n",
        "%cd ../\n",
        "!mv Final_Results NWPU_Results\n",
        "!rm -r NWPU-Crowd-Sample-Code\n",
        "!rm /content/frames/test1.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-kuk7gHvBwP"
      },
      "source": [
        "## To Zip NWPU files and then have to get shareable link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUN-ObA5QGcv"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hq0SVyVfvDvB"
      },
      "outputs": [],
      "source": [
        "# %cd /content/drive/MyDrive/\n",
        "# !zip -r NWPU.zip './NWPU-Crowd-Sample-Code'\n",
        "# %cd ../../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh_ui4kmLvBw"
      },
      "source": [
        "# FlowNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OGCfYuDTz7n"
      },
      "source": [
        "## Setup and Install FlowNet2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMRndXGRFDJo"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.0.0 torchvision==0.2.2 -f https://download.pytorch.org/whl/cu100/torch_stable.html\n",
        "!pip install pypng\n",
        "!pip install tensorboardx\n",
        "!pip install setproctitle colorama scipy==1.1.0\n",
        "!pip install flowiz -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWy52WXkEX7M"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# get flownet2-pytorch source\n",
        "!git clone https://github.com/NVIDIA/flownet2-pytorch.git\n",
        "!mv /content/flownet2-pytorch /content/flownet2pytorch\n",
        "os.chdir('./flownet2pytorch')\n",
        "# install custom layers\n",
        "!bash install.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVwu6EIMVj2C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/resample2d_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append('/root/.local/lib/python3.6/site-packages/correlation_cuda-0.0.0-py3.6-linux-x86_64.egg')\n",
        "os.sys.path.append( '/root/.local/lib/python3.6/site-packages/channelnorm_cuda-0.0.0-py3.6-linux-x86_64.egg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tekc8kk_Ehft"
      },
      "outputs": [],
      "source": [
        "!python main.py --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVqbeGLwLGfJ"
      },
      "source": [
        "## Training and Validation - Not tested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBj_0jWLKci"
      },
      "source": [
        "If you do not want to train your model, you can skip this and move on to inference.\n",
        "\n",
        "The dataset my team used is quite large and we have unlimited storage on OneDrive. So we have mounted OneDrive to read and write data to. <br>\n",
        "To understand how to use it: https://www.youtube.com/watch?v=U6YPgARhRzA&t=255s&ab_channel=BoostUpStation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVqSGUtKLlVA"
      },
      "source": [
        "### OneDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYM_bz-zLbyj"
      },
      "outputs": [],
      "source": [
        "# !wget https://downloads.rclone.org/v1.50.1/rclone-v1.50.1-linux-amd64.deb\n",
        "# !apt install ./rclone-v1.50.1-linux-amd64.deb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEbqhaQRLiAe"
      },
      "outputs": [],
      "source": [
        "# !rclone config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DKu50aALjjY"
      },
      "outputs": [],
      "source": [
        "# !sudo mkdir /content/onedrive\n",
        "# !nohup rclone --vfs-cache-mode writes mount onedrive: /content/onedrive &"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phyZO2lSLqla"
      },
      "source": [
        "### Train and Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y9f7R1gLu3w"
      },
      "outputs": [],
      "source": [
        "# !python main.py --batch_size 8 --model FlowNet2 --loss=L1Loss --optimizer=Adam --optimizer_lr=1e-4 \\\n",
        "# --training_dataset MpiSintelFinal --training_dataset_root /path/to/mpi-sintel/final/dataset  \\\n",
        "# --validation_dataset MpiSintelClean --validation_dataset_root /path/to/mpi-sintel/clean/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9C7PFQ8U9b6"
      },
      "source": [
        "## Run inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmez3yOUKkQx"
      },
      "source": [
        "Download the checkpoint. <br>\n",
        "If you have your own checkpoint after training, skip this step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePuj4IqqGk_k"
      },
      "outputs": [],
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1hF8vS6YeHkx3j2pfCeQqqZGwA_PJq_Da',dest_path='./FlowNet2_checkpoint.pth.tar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZn6AR6VKqMb"
      },
      "source": [
        "Run inference. <br>\n",
        "You can learn more about each command from here: https://towardsdatascience.com/generating-optical-flow-using-nvidia-flownet2-pytorch-implementation-d7b0ae6f8320"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOJoEKsHS1n1"
      },
      "outputs": [],
      "source": [
        "!python main.py --inference --model FlowNet2 --save_flow --save ./output --inference_dataset ImagesFromFolder --inference_dataset_root ../frames/ --resume ./FlowNet2_checkpoint.pth.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex7-_aXHaBUm"
      },
      "source": [
        "## Average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWJvO63kaDbM"
      },
      "outputs": [],
      "source": [
        "if running_average == True or no_average_frames != None:\n",
        "  import numpy as np\n",
        "  from pathlib import Path\n",
        "  import os\n",
        "  from utils.flow_utils import writeFlow\n",
        "\n",
        "  def write_frame_ra(flow, i):\n",
        "    dir = \"./Running_Avg_Frames/\" + str(i).zfill(6) + \".flo\"\n",
        "    writeFlow(dir, flow)\n",
        "\n",
        "  def write_frame_avg(flow, i):\n",
        "    dir = \"./Average_Frames/\" + str(i).zfill(6) + \".flo\"\n",
        "    writeFlow(dir, flow)\n",
        "\n",
        "  def average_list(list1):\n",
        "    length_list = len(list1)\n",
        "    temp_addition = 0\n",
        "    for i in range(0, length_list):\n",
        "        temp_addition += list1[i]\n",
        "    temp_val = temp_addition / length_list\n",
        "    return temp_val\n",
        "    # try:\n",
        "    #   return (list1[0] + list1[1]) / 2\n",
        "    # except:\n",
        "    #   print(\"Error in averaging\")\n",
        "\n",
        "  def make_flow(flo):\n",
        "    tag = np.fromfile(flo, np.float32, count=1)[0]\n",
        "    width = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    height = np.fromfile(flo, np.int32, count=1)[0]\n",
        "    nbands = 2\n",
        "    tmp = np.fromfile(flo, np.float32, count= nbands * width * height)\n",
        "    flow = np.resize(tmp, (int(height), int(width), int(nbands)))\n",
        "    return flow\n",
        "\n",
        "  if no_average_frames != None:\n",
        "    flow_list = [None] * no_average_frames\n",
        "    index_flow = 0\n",
        "    index_name = 0\n",
        "\n",
        "  numerator = 0\n",
        "  denominator = 0\n",
        "  index_name = 0\n",
        "\n",
        "  !mkdir ./Running_Avg_Frames\n",
        "  !mkdir ./Average_Frames\n",
        "  dir = './output/inference/run.epoch-0-flow-field/'\n",
        "\n",
        "  for i, flo_file in enumerate(sorted(os.listdir(dir))):\n",
        "    if flo_file[-3:] != \"flo\":\n",
        "      continue\n",
        "\n",
        "    path = Path(dir + flo_file)\n",
        "    with path.open(mode='r') as flo:\n",
        "      final_flo = make_flow(flo) # From their own code\n",
        "\n",
        "      if running_average == True and no_average_frames == None:\n",
        "        # Method 4\n",
        "        if denominator == 0:\n",
        "          numerator += final_flo\n",
        "          denominator = 1\n",
        "        else:\n",
        "          numerator += final_flo\n",
        "          denominator +=1\n",
        "\n",
        "          average_flow = numerator/denominator\n",
        "\n",
        "          write_frame(average_flow, index_name)\n",
        "          index_name += 1\n",
        "          \n",
        "        # os.remove(dir + flo_file)\n",
        "\n",
        "      # Method 3\n",
        "      if running_average == False and no_average_frames != None:\n",
        "        if (index_flow % no_average_frames == 0) and index_flow != 0:\n",
        "          average_flow = average_list(flow_list)\n",
        "          write_frame_ra(average_flow, index_name)\n",
        "          index_flow = 0\n",
        "          index_name += 1\n",
        "\n",
        "        flow_list[index_flow] = final_flo\n",
        "        index_flow += 1\n",
        "\n",
        "        if i == len(os.listdir(dir)) - 1:\n",
        "          average_flow = average_list(flow_list)\n",
        "          write_frame_avg(average_flow, index_name)\n",
        "\n",
        "        os.remove(dir + flo_file)\n",
        "\n",
        "      # Method 1\n",
        "      # if i == 0:\n",
        "      #   flow_list[0] = flow\n",
        "      # else:\n",
        "      #   flow_list[1] = flow\n",
        "      #   average_flow = average_list(flow_list)\n",
        "      #   write_frame(average_flow, i-1)\n",
        "      #   flow_list[0] = average_flow\n",
        "\n",
        "      # Method 2\n",
        "      # if index_flow == 0:\n",
        "      #   flow_list[index_flow] = flow\n",
        "      #   index_flow += 1\n",
        "      # else:\n",
        "      #   flow_list[index_flow] = flow\n",
        "      #   index_flow = 0\n",
        "      #   average_flow = average_list(flow_list)\n",
        "      #   write_frame(average_flow, index_name)\n",
        "      #   index_name += 1\n",
        "\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-EUe_yX5wwC"
      },
      "source": [
        "## Visualizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcPNFZh04-YE"
      },
      "source": [
        "### Flowiz technique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBogYWu65HQe"
      },
      "outputs": [],
      "source": [
        "# if visualize == True:\n",
        "\n",
        "#   !python -m flowiz \\\n",
        "#   ./Flo/*.flo \\\n",
        "#   -o FlowFrames \\\n",
        "#   -v FlowVideo \\\n",
        "#   -r 15\n",
        "\n",
        "#   !mv ./FlowVideo/000000.flo.mp4 './FlowVideo/$flow_video_name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpdC2-7o-V3p"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('./FlowVideo/'+flow_video_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBSvCvj5XPMX"
      },
      "source": [
        "### Scipy Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5j8_TkanL0_"
      },
      "source": [
        "Install scipy as some tensorflow functionality requires updated scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb5ZMFHcl_jw"
      },
      "outputs": [],
      "source": [
        "if visualize == True:\n",
        "  import time\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  !pip install scipy==1.4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihUwCSdnXlge"
      },
      "source": [
        "Define show_flow() for visualization.\n",
        " Original Source https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGwMS0x0XaJC"
      },
      "outputs": [],
      "source": [
        "# Source:https://github.com/sampepose/flownet2-tf/blob/master/src/flowlib.py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "UNKNOWN_FLOW_THRESH = 1e7\n",
        "def show_flow(filename):\n",
        "    \"\"\"\n",
        "    visualize optical flow map using matplotlib\n",
        "    :param filename: optical flow file\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    flow = read_flow(filename)\n",
        "    img = flow_to_image(flow)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "def read_flow(filename):\n",
        "    \"\"\"\n",
        "    read optical flow from Middlebury .flo file\n",
        "    :param filename: name of the flow file\n",
        "    :return: optical flow data in matrix\n",
        "    \"\"\"\n",
        "    f = open(filename, 'rb')\n",
        "    magic = np.fromfile(f, np.float32, count=1)\n",
        "    data2d = None\n",
        "\n",
        "    if 202021.25 != magic:\n",
        "        print ('Magic number incorrect. Invalid .flo file')\n",
        "    else:\n",
        "        w = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        h = int(np.fromfile(f, np.int32, count=1)[0])\n",
        "        #print(\"Reading %d x %d flo file\" % (h, w))\n",
        "        data2d = np.fromfile(f, np.float32, count=2 * w * h)\n",
        "        # reshape data into 3D array (columns, rows, channels)\n",
        "        data2d = np.resize(data2d, (h, w, 2))\n",
        "    f.close()\n",
        "    return data2d\n",
        "\n",
        "def flow_to_image(flow):\n",
        "    \"\"\"\n",
        "    Convert flow into middlebury color code image\n",
        "    :param flow: optical flow map\n",
        "    :return: optical flow image in middlebury color\n",
        "    \"\"\"\n",
        "    u = flow[:, :, 0]\n",
        "    v = flow[:, :, 1]\n",
        "\n",
        "    maxu = -999.\n",
        "    maxv = -999.\n",
        "    minu = 999.\n",
        "    minv = 999.\n",
        "\n",
        "    idxUnknow = (abs(u) > UNKNOWN_FLOW_THRESH) | (abs(v) > UNKNOWN_FLOW_THRESH)\n",
        "    u[idxUnknow] = 0\n",
        "    v[idxUnknow] = 0\n",
        "\n",
        "    maxu = max(maxu, np.max(u))\n",
        "    minu = min(minu, np.min(u))\n",
        "\n",
        "    maxv = max(maxv, np.max(v))\n",
        "    minv = min(minv, np.min(v))\n",
        "\n",
        "    rad = np.sqrt(u ** 2 + v ** 2)\n",
        "    maxrad = max(-1, np.max(rad))\n",
        "\n",
        "    #print( \"max flow: %.4f\\nflow range:\\nu = %.3f .. %.3f\\nv = %.3f .. %.3f\" % (maxrad, minu,maxu, minv, maxv))\n",
        "\n",
        "    u = u/(maxrad + np.finfo(float).eps)\n",
        "    v = v/(maxrad + np.finfo(float).eps)\n",
        "\n",
        "    img = compute_color(u, v)\n",
        "\n",
        "    idx = np.repeat(idxUnknow[:, :, np.newaxis], 3, axis=2)\n",
        "    img[idx] = 0\n",
        "\n",
        "    return np.uint8(img)\n",
        "\n",
        "\n",
        "def compute_color(u, v):\n",
        "    \"\"\"\n",
        "    compute optical flow color map\n",
        "    :param u: optical flow horizontal map\n",
        "    :param v: optical flow vertical map\n",
        "    :return: optical flow in color code\n",
        "    \"\"\"\n",
        "    [h, w] = u.shape\n",
        "    img = np.zeros([h, w, 3])\n",
        "    nanIdx = np.isnan(u) | np.isnan(v)\n",
        "    u[nanIdx] = 0\n",
        "    v[nanIdx] = 0\n",
        "\n",
        "    colorwheel = make_color_wheel()\n",
        "    ncols = np.size(colorwheel, 0)\n",
        "\n",
        "    rad = np.sqrt(u**2+v**2)\n",
        "\n",
        "    a = np.arctan2(-v, -u) / np.pi\n",
        "\n",
        "    fk = (a+1) / 2 * (ncols - 1) + 1\n",
        "\n",
        "    k0 = np.floor(fk).astype(int)\n",
        "\n",
        "    k1 = k0 + 1\n",
        "    k1[k1 == ncols+1] = 1\n",
        "    f = fk - k0\n",
        "\n",
        "    for i in range(0, np.size(colorwheel,1)):\n",
        "        tmp = colorwheel[:, i]\n",
        "        col0 = tmp[k0-1] / 255\n",
        "        col1 = tmp[k1-1] / 255\n",
        "        col = (1-f) * col0 + f * col1\n",
        "\n",
        "        idx = rad <= 1\n",
        "        col[idx] = 1-rad[idx]*(1-col[idx])\n",
        "        notidx = np.logical_not(idx)\n",
        "\n",
        "        col[notidx] *= 0.75\n",
        "        img[:, :, i] = np.uint8(np.floor(255 * col*(1-nanIdx)))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def make_color_wheel():\n",
        "    \"\"\"\n",
        "    Generate color wheel according Middlebury color code\n",
        "    :return: Color wheel\n",
        "    \"\"\"\n",
        "    RY = 15\n",
        "    YG = 6\n",
        "    GC = 4\n",
        "    CB = 11\n",
        "    BM = 13\n",
        "    MR = 6\n",
        "\n",
        "    ncols = RY + YG + GC + CB + BM + MR\n",
        "\n",
        "    colorwheel = np.zeros([ncols, 3])\n",
        "\n",
        "    col = 0\n",
        "\n",
        "    # RY\n",
        "    colorwheel[0:RY, 0] = 255\n",
        "    colorwheel[0:RY, 1] = np.transpose(np.floor(255*np.arange(0, RY) / RY))\n",
        "    col += RY\n",
        "\n",
        "    # YG\n",
        "    colorwheel[col:col+YG, 0] = 255 - np.transpose(np.floor(255*np.arange(0, YG) / YG))\n",
        "    colorwheel[col:col+YG, 1] = 255\n",
        "    col += YG\n",
        "\n",
        "    # GC\n",
        "    colorwheel[col:col+GC, 1] = 255\n",
        "    colorwheel[col:col+GC, 2] = np.transpose(np.floor(255*np.arange(0, GC) / GC))\n",
        "    col += GC\n",
        "\n",
        "    # CB\n",
        "    colorwheel[col:col+CB, 1] = 255 - np.transpose(np.floor(255*np.arange(0, CB) / CB))\n",
        "    colorwheel[col:col+CB, 2] = 255\n",
        "    col += CB\n",
        "\n",
        "    # BM\n",
        "    colorwheel[col:col+BM, 2] = 255\n",
        "    colorwheel[col:col+BM, 0] = np.transpose(np.floor(255*np.arange(0, BM) / BM))\n",
        "    col += + BM\n",
        "\n",
        "    # MR\n",
        "    colorwheel[col:col+MR, 2] = 255 - np.transpose(np.floor(255 * np.arange(0, MR) / MR))\n",
        "    colorwheel[col:col+MR, 0] = 255\n",
        "\n",
        "    return colorwheel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itvl1OTiYMSd"
      },
      "source": [
        "Save Flo files as images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YopuaMoJPYnT"
      },
      "outputs": [],
      "source": [
        "if visualize == True:\n",
        "\n",
        "  import os\n",
        "  import PIL.Image\n",
        "  def mkdir_ifnotexists(dir):\n",
        "      if os.path.exists(dir):\n",
        "          return\n",
        "      os.mkdir(dir)\n",
        "\n",
        "  if no_average_frames != None:\n",
        "    directory = \"./Average_Frames\"\n",
        "\n",
        "  elif running_average == True:\n",
        "    directory = \"./Running_Avg_Frames\"\n",
        "\n",
        "  else:\n",
        "    directory = '/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "\n",
        "  # flo_pth='/content/flownet2pytorch/output/inference/run.epoch-0-flow-field/'\n",
        "  flo_pth = directory\n",
        "  flos=[flo_pth + f for f in os.listdir(flo_pth)]\n",
        "  mkdir_ifnotexists('./FlowFrames')\n",
        "  length = len(flos)\n",
        "  for i in range(length):\n",
        "    if flos[i][-3:] == \"flo\":\n",
        "      print(i+1, \"/\", length)\n",
        "      PIL.Image.fromarray(flow_to_image(read_flow(flos[i]))).save('./FlowFrames/'+os.path.basename(flos[i])+'.png')\n",
        "      os.remove(flos[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HXMqwKjYT32"
      },
      "source": [
        "Generate video from Flo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGPockiXSpri"
      },
      "outputs": [],
      "source": [
        "if visualize == True:\n",
        "  os.system('ffmpeg -r 25 -i FlowFrames/%6d.flo.png -vcodec libx264 -b 10M -y FlowVideo.mp4')\n",
        "\n",
        "  print(\"My program took\", time.time() - start_time, \"to run\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWvhMuDdl1GG"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('FlowVideo.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i_mPe1OYoTi"
      },
      "outputs": [],
      "source": [
        "if visualize == True:\n",
        "\n",
        "  from IPython.display import HTML\n",
        "  from base64 import b64encode\n",
        "  mp4 = open('FlowVideo.mp4','rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  HTML(\"\"\"\n",
        "  <video width=400 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1owR4iebzvF"
      },
      "source": [
        "# Head Coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHVMGwXicsdc",
        "outputId": "83c3d4c6-555a-49e1-e744-018081ce817a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/\n",
        "\n",
        "frames = []\n",
        "dir = 'NWPU_Results/'\n",
        "\n",
        "for file in sorted(os.listdir('./NWPU_Results')):\n",
        "  if file[-3:] == 'csv':\n",
        "    frames.append(dir + file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni8lheCUb1Y9",
        "outputId": "f48c69a3-c848-4890-8aa3-034574a3f245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 34\n",
            "1  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 32\n",
            "2  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "3  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "4  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 11\n",
            "5  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 11\n",
            "6  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "7  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "8  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "9  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "10  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "11  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "12  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "13  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "14  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "15  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "16  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "17  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "18  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "19  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 20\n",
            "20  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "21  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "22  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 25\n",
            "23  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "24  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "25  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "26  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "27  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "28  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "29  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 8\n",
            "30  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 7\n",
            "31  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 9\n",
            "32  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "33  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 6\n",
            "34  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "35  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 5\n",
            "36  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "37  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "38  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "39  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "40  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "41  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "42  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 8\n",
            "43  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 7\n",
            "44  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "45  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "46  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 20\n",
            "47  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "48  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "49  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "50  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "51  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 28\n",
            "52  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 36\n",
            "53  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 23\n",
            "54  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "55  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 29\n",
            "56  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "57  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 13\n",
            "58  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "59  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "60  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 25\n",
            "61  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 26\n",
            "62  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "63  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "64  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "65  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 20\n",
            "66  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "67  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "68  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "69  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 15\n",
            "70  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "71  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "72  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "73  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 12\n",
            "74  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "75  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 19\n",
            "76  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "77  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "78  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 24\n",
            "79  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 23\n",
            "80  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "81  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 16\n",
            "82  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 10\n",
            "83  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 14\n",
            "84  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 24\n",
            "85  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 18\n",
            "86  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 17\n",
            "87  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 21\n",
            "88  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 22\n",
            "89  /  90\n",
            "(1024, 1920)\n",
            "Number of people: 23\n"
          ]
        }
      ],
      "source": [
        "# Import\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "f = open(\"temp.txt\", 'w')\n",
        "\n",
        "# Set Values\n",
        "threshold = 0.5 * (10**(-1))\n",
        "weight = 2\n",
        "\n",
        "for i, frame in enumerate(frames[1:]):\n",
        "    print(i, \" / \", len(frames)-1)\n",
        "\n",
        "    # Get Excel Sheet\n",
        "    X = np.genfromtxt(frame, delimiter=',')\n",
        "\n",
        "    os.remove(frame)\n",
        "\n",
        "    points_val = X\n",
        "\n",
        "    print(X.shape)\n",
        "\n",
        "    # First value is always nan for some reason\n",
        "    X[0][0] = 0\n",
        "\n",
        "    # Total Value\n",
        "    total_val = np.sum(X)\n",
        "    number_people = int(round(np.sum(X)/100))\n",
        "    print(\"Number of people:\", number_people)\n",
        "\n",
        "    vals = X[X[:,:] > threshold] # Contains the values. 1D array\n",
        "\n",
        "    index = np.argwhere(points_val > threshold) # Contains the index. 2D array.\n",
        "\n",
        "    # Making a 2D Array with point, val -> (x, y, val)\n",
        "    list_for_cluster = [] # Contains a 2D array with point, val\n",
        "\n",
        "    for i, point in enumerate(index):\n",
        "        val = vals[i]\n",
        "        list_for_cluster.append(np.append(point, val))\n",
        "\n",
        "    final_list = np.array(list_for_cluster) # Contains a 2D array with point, val -> (x, y, val)\n",
        "    final_list.shape\n",
        "\n",
        "    x_index = index[:,0]\n",
        "    y_index = index[:,1]\n",
        "\n",
        "    cluster_vals = index\n",
        "\n",
        "    weights = vals ** weight\n",
        "\n",
        "    # Cluster based on K Means Clustering\n",
        "    # Forcefully put how many ever people we found, make that many clusters\n",
        "\n",
        "    kmeans = KMeans(\n",
        "        init=\"random\",\n",
        "        n_clusters=number_people,\n",
        "        n_init=10,\n",
        "        max_iter=500,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    kmeans.fit(cluster_vals, sample_weight = weights)\n",
        "\n",
        "    kmeans.inertia_\n",
        "    kmeans.cluster_centers_\n",
        "    kmeans.n_iter_\n",
        "    y_kmeans = kmeans.predict(cluster_vals)\n",
        "\n",
        "    centers = kmeans.cluster_centers_\n",
        "\n",
        "    # Write to cords.txt\n",
        "    line = \"\"\n",
        "    for center in centers:\n",
        "        line += str(int(center[1])) + \" \" + str(int(center[0])) + \" \"\n",
        "\n",
        "    line = line.strip()\n",
        "    line += \"\\n \"\n",
        "\n",
        "    f.write(line)\n",
        "\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6P-9seb5HAW"
      },
      "outputs": [],
      "source": [
        "cords = open(\"cords.txt\", 'w')\n",
        "temp = open(\"temp.txt\", 'r')\n",
        "temp_lines = temp.read().split(\"\\n\")\n",
        "\n",
        "for i, line in enumerate(temp_lines):\n",
        "  fline = line.strip()\n",
        "  if i != len(temp_lines) - 1:\n",
        "    fline += \"\\n\"\n",
        "  cords.write(fline)\n",
        "\n",
        "cords.close()\n",
        "temp.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPnauiE5sNLV"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4AwX9BZmv36"
      },
      "source": [
        "## Manual Annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oKtWXy6m1nQ"
      },
      "source": [
        "\n",
        "\n",
        "1.   Take any frame from the folder frames. RENAME it to 'image.png'\n",
        "2.   Run the file \"annotate.py\" from the github folder\n",
        "3.   Paste the output text file \"text_speed.txt\" in the same folder as the \"cords.txt\". This is the /content/ directory\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWeidUMPnl43"
      },
      "source": [
        "HOW TO RUN ANNOTATE.PY\n",
        "\n",
        "0.   Keep the annotate.py and the first frame in the same directory and run 'python annotate.py'\n",
        "1.   Annotate the first and second x meters\n",
        "2.   Annotate the road in a clockwise fashion starting from where you marked the first x meters\n",
        "3.   Fil these variables:\n",
        "\n",
        "  *   temp_approx_meters_p1 = 0.5 # How many meters the first x meters represents\n",
        "  *   temp_approx_meters_p2 = 0.5 # How many meters the second y meters represents\n",
        "  *   normalize_meters = 1 # If you want the output to be represented in some other amount of meters, do that here. For eg. if you have annotated first point as 0.5m and second as 1m and want the output to be catered to by 1m, then make this 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pewBZr7pmyGH",
        "outputId": "ed8ed95a-2b76-47cb-b57a-105f405469e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'text_speed.txt': No such file or directory\n",
            "/content/Clustering\n",
            "mv: cannot stat 'text_speed.txt': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "!mkdir Clustering\n",
        "\n",
        "!mv cords.txt text_speed.txt Clustering\n",
        "\n",
        "%cd Clustering\n",
        "\n",
        "!mkdir text_files\n",
        "!mkdir output_frames\n",
        "\n",
        "!mv cords.txt text_speed.txt text_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVKQ6WDAsU0w"
      },
      "source": [
        "## Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTp34fkdsOjq",
        "outputId": "641de1f5-ceb1-4684-abbc-84269350d8ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'NVIDIA-FlowNet2-Google-Colab'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 107 (delta 49), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (107/107), 48.13 MiB | 12.88 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JibKh/NVIDIA-FlowNet2-Google-Colab.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjRiYwsysr5v",
        "outputId": "2bbb85df-40d2-4c41-c6fe-3e2584c7b75f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Clustering/NVIDIA-FlowNet2-Google-Colab\n",
            "/content/Clustering\n"
          ]
        }
      ],
      "source": [
        "%cd NVIDIA-FlowNet2-Google-Colab/\n",
        "!mv cluster.py /content/Clustering\n",
        "%cd ..\n",
        "!rm -r NVIDIA-FlowNet2-Google-Colab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE54AYiy2UFw"
      },
      "outputs": [],
      "source": [
        "# Have to remove first frame and rename\n",
        "!rm /content/frames/000000.png\n",
        "\n",
        "\n",
        "file_dir = \"/content/frames/\"\n",
        "i = 0\n",
        "for count, filename in enumerate(sorted(os.listdir(file_dir))):\n",
        "  # print(filename)\n",
        "  if filename[-3:] == \"png\":\n",
        "    src = file_dir + filename\n",
        "    dst = file_dir + str(i).zfill(6) + '.png'\n",
        "    os.rename(src, dst)\n",
        "    i += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr2YuBcptXPZ",
        "outputId": "e58f0dca-3d0f-4147-b344-fbebc8566841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"cluster.py\", line 496, in <module>\n",
            "    main()\n",
            "  File \"cluster.py\", line 486, in main\n",
            "    points_labels, velocity_labels, speed_labels, average_speed, total_average_speed = cluster_2()\n",
            "  File \"cluster.py\", line 262, in cluster_2\n",
            "    total_total += total_average_speed\n",
            "NameError: name 'total_total' is not defined\n"
          ]
        }
      ],
      "source": [
        "!python cluster.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FzQbslOva0s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "FlowNet2_Colab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('hajjenv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "4ed1606e3c91447926a63651035afd07f0b3140ffe583749547873f87055fbe9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
